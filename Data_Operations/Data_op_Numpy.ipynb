{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy**\n",
        "\n",
        "NumPy is a Python library used for working with arrays.\n",
        "\n",
        "It also has functions for working in domain of linear algebra, fourier transform, and matrices.\n",
        "\n",
        "NumPy was created in 2005 by Travis Oliphant. It is an open source project and you can use it freely.\n",
        "\n",
        "NumPy stands for Numerical Python.In Python we have lists that serve the purpose of arrays, but they are slow to process.\n",
        "\n",
        "NumPy aims to provide an array object that is up to 50x faster than traditional Python lists.\n",
        "\n",
        "The array object in NumPy is called ndarray, it provides a lot of supporting functions that make working with ndarray very easy.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9krlu1RQQwBM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXDyu1h1N1Ns",
        "outputId": "6f4f75cc-bec2-4902-8061-20c0dffa13aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [2.83106871e-15 2.00000000e+00 3.00000000e+00]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "X_b = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "X_new = np.array([[0], [2], [3]])\n",
        "X_new_b = np.c_[np.ones((len(X_new), 1)), X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "\n",
        "print(\"Predictions:\", y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m = len(y)\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    theta = np.random.randn(X_b.shape[1], 1)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        z = X_b.dot(theta)\n",
        "        predictions = sigmoid(z)\n",
        "        gradients = X_b.T.dot(predictions - y) / m\n",
        "        theta -= learning_rate * gradients\n",
        "\n",
        "    return theta\n",
        "\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([[0], [0], [1], [1]])\n",
        "\n",
        "theta_best = gradient_descent(X, y, learning_rate=0.1, iterations=1000)\n",
        "print(\"Best parameters:\", theta_best)\n",
        "\n",
        "X_new = np.array([[1], [3]])\n",
        "X_new_b = np.c_[np.ones((len(X_new), 1)), X_new]\n",
        "predictions = sigmoid(X_new_b.dot(theta_best))\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ0Xs-QUPeU0",
        "outputId": "1accbf2f-6438-4ad6-aba7-f215c57077af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: [[-5.55407835]\n",
            " [ 2.33133747]]\n",
            "Predictions: [[0.03831885]\n",
            " [0.80844444]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Distance function\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "# K-NN classifier\n",
        "def knn(X_train, y_train, X_test, k=3):\n",
        "    y_pred = []\n",
        "    for test_point in X_test:\n",
        "        distances = [euclidean_distance(test_point, x) for x in X_train]\n",
        "        k_indices = np.argsort(distances)[:k]\n",
        "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
        "        majority_vote = Counter(k_nearest_labels).most_common(1)[0][0]\n",
        "        y_pred.append(majority_vote)\n",
        "    return y_pred\n",
        "\n",
        "# Sample data\n",
        "X_train = np.array([[1, 1], [2, 2], [3, 3], [6, 6], [7, 7]])\n",
        "y_train = np.array([0, 0, 0, 1, 1])\n",
        "X_test = np.array([[4, 4], [5, 5]])\n",
        "\n",
        "# Run K-NN classifier\n",
        "y_pred = knn(X_train, y_train, X_test, k=3)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyOa8W0vPtYo",
        "outputId": "f9e86543-4c80-4286-c8ec-b72466fb6491"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: [0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (each row is a data point)\n",
        "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0]])\n",
        "\n",
        "# Standardize data (zero mean and unit variance)\n",
        "X_meaned = X - np.mean(X, axis=0)\n",
        "\n",
        "# Covariance matrix\n",
        "cov_matrix = np.cov(X_meaned.T)\n",
        "\n",
        "# Eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "# Sort eigenvectors by eigenvalues in decreasing order\n",
        "idx = eigenvalues.argsort()[::-1]\n",
        "eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "# Transform the data to the new basis\n",
        "X_pca = X_meaned.dot(eigenvectors)\n",
        "\n",
        "print(\"PCA transformed data:\\n\", X_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sQIV0x8Pyxk",
        "outputId": "409a1a2d-77a1-4e0e-d81d-81d3cd978dc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA transformed data:\n",
            " [[ 0.44362444 -0.20099093]\n",
            " [-2.17719404 -0.05500992]\n",
            " [ 0.57071239  0.36808609]\n",
            " [-0.12902465  0.06747325]\n",
            " [ 1.29188186 -0.17955849]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Euclidean distance\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "# K-Means algorithm\n",
        "def kmeans(X, k, iterations):\n",
        "    # Randomly initialize centroids\n",
        "    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Assign points to the nearest centroid\n",
        "        clusters = [[] for _ in range(k)]\n",
        "        for point in X:\n",
        "            distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "            cluster_index = np.argmin(distances)\n",
        "            clusters[cluster_index].append(point)\n",
        "\n",
        "        # Update centroids\n",
        "        new_centroids = np.array([np.mean(cluster, axis=0) for cluster in clusters])\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return centroids, clusters\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
        "\n",
        "# Run K-Means\n",
        "centroids, clusters = kmeans(X, k=2, iterations=100)\n",
        "print(\"Centroids:\\n\", centroids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAOUVis6P-N0",
        "outputId": "e00f7ea4-7cd0-4b86-c15f-f9f253dc8d6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids:\n",
            " [[7.33333333 9.        ]\n",
            " [1.16666667 1.46666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate probabilities\n",
        "def calculate_probabilities(X, y):\n",
        "    unique_classes = np.unique(y)\n",
        "    probabilities = {}\n",
        "\n",
        "    for label in unique_classes:\n",
        "        X_class = X[y == label]\n",
        "        probabilities[label] = {}\n",
        "        probabilities[label]['prior'] = len(X_class) / len(y)\n",
        "        probabilities[label]['mean'] = np.mean(X_class, axis=0)\n",
        "        probabilities[label]['var'] = np.var(X_class, axis=0)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "# Gaussian probability\n",
        "def gaussian_probability(x, mean, var):\n",
        "    coeff = 1 / np.sqrt(2 * np.pi * var)\n",
        "    exponent = np.exp(-(x - mean)**2 / (2 * var))\n",
        "    return coeff * exponent\n",
        "\n",
        "# Predict class label\n",
        "def predict(X_test, probabilities):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        posteriors = {}\n",
        "        for label, params in probabilities.items():\n",
        "            prior = np.log(params['prior'])\n",
        "            likelihood = np.sum(np.log(gaussian_probability(x, params['mean'], params['var'])))\n",
        "            posteriors[label] = prior + likelihood\n",
        "        predictions.append(max(posteriors, key=posteriors.get))\n",
        "    return predictions\n",
        "\n",
        "# Sample data\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y_train = np.array([0, 0, 1, 1, 1])\n",
        "X_test = np.array([[2.5, 3.5], [3.5, 4.5]])\n",
        "\n",
        "# Run Naive Bayes classifier\n",
        "probabilities = calculate_probabilities(X_train, y_train)\n",
        "y_pred = predict(X_test, probabilities)\n",
        "print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bikRwXHZQBx2",
        "outputId": "92d64633-1802-4b22-833b-dd7c756fd206"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hinge loss function for SVM\n",
        "def hinge_loss(X, y, w, b, reg_strength):\n",
        "    n_samples = X.shape[0]\n",
        "    distances = 1 - y * (np.dot(X, w) + b)\n",
        "    losses = np.maximum(0, distances)\n",
        "    return reg_strength * (np.sum(losses) / n_samples)\n",
        "\n",
        "# Gradient descent for SVM\n",
        "def gradient_descent(X, y, w, b, learning_rate, iterations, reg_strength):\n",
        "    for _ in range(iterations):\n",
        "        for i, x_i in enumerate(X):\n",
        "            condition = y[i] * (np.dot(X[i], w) + b) >= 1\n",
        "            if condition:\n",
        "                w -= learning_rate * (2 * reg_strength * w)\n",
        "            else:\n",
        "                w -= learning_rate * (2 * reg_strength * w - np.dot(X[i], y[i]))\n",
        "                b -= learning_rate * y[i]\n",
        "    return w, b\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [4, 5], [5, 6]])\n",
        "y = np.array([1, 1, -1, -1, -1])\n",
        "\n",
        "# Parameters\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "learning_rate = 0.001\n",
        "iterations = 1000\n",
        "reg_strength = 0.01\n",
        "\n",
        "# Train SVM\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, iterations, reg_strength)\n",
        "print(\"Weight vector:\", w)\n",
        "print(\"Bias term:\", b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fLOQ9NTQHyx",
        "outputId": "14874853-da76-4462-98ee-0aba9e30d3c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight vector: [-0.72999255  0.57392065]\n",
            "Bias term: -0.9520000000000007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_LltKQiQLiY"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}